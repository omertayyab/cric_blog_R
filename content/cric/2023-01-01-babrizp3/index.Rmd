---
title: The Babar Rizwan Question, Part 3
author: OT
date: '2023-01-01'
slug: BabRizP3
categories:
  - analysis
  - cricket
  - data
  - data science
  - R
tags:
  - analysis
  - cricket
  - data
  - data science
  - plot
  - R Markdown
  - regression
  - correlation
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(here)
library(cricketdata)
library(tidyverse)
library(knitr)
library(kableExtra)
library(gt)
library(ggplot2)
library(ggthemes)

knitr::opts_chunk$set(echo = TRUE, error = FALSE, warning = FALSE, message = FALSE)
all_data <- readRDS(here("static","data","R_objects","all_data.rds"))
Pak_data <- readRDS(here("static","data","R_objects","Pak_data.rds"))
overs <- readRDS(here("static","data","R_objects","overs.rds"))
result_wk1_pp <- readRDS(here("static","data","R_objects","result_wk1_pp.rds"))
`%!in%` <- Negate(`%in%`)
```

This is an R Markdown document^[Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For downloading the R Markdown file that generated this webpage, visit my [GitHub](https://github.com/omertayyab/cric_blog_R). For more details on using R Markdown, use this [link](http://rmarkdown.rstudio.com)].

# Introduction

In the previous part, we had scene the table below:
```{r Pakistan_matches, echo=FALSE, cache=TRUE}
options(kableExtra.html.bsTable = TRUE)

result_wk1_pp %>%
  select(.,c(1,4:8)) %>%
  kbl(.,
      align = "c",
      digits=1,
      col.names = gsub("_"," ",colnames(result_wk1_pp)[c(1,4:8)])
      ) %>%
  kable_styling(bootstrap_options = c("striped","hover"))
```
We had concluded that the Powerplay impact of the openers was quite close to other top teams so it must actually be the later phases of the innings where Pakistan is lacking (as shown by the difference in final scores). However, we'd still like to quantify how PP scores affect the final score, so we'll look at that question.

We can also see here that Pakistan actually lost more wickets than other top teams at the end of their innings, while losing less in the Powerplay. All of this information points to the direction of Pak's usage of the overs 7-20. So, now we'll focus our analysis on that part as well.

# Powerplay and Final Score

Finally we get to do some data science after all the data wrangling of the last 2 parts! We will start off slowly. It is reasonable to expect that the final total of a team must have some positive correlation with the score in the Powerplay. So, we'll take the 2 elements of the PP score that could have positive correlation with the final total (i.e. runs and wickets remaining) as independent variables and run some type of regression (we'll figure this out below) against the final score (set as the dependent variable).

## Setting up the regression
Before we run a regression,we have to check that the independent variables are not correlated to each other because that violates a key assumption of the linear regression model. We will also have to decide on a sample size. Since we are looking at a general relationship between Powerplay performance and final scores, we don't really have any limitations and we can look at the entire history of T20I games for our top 5 teams plus West Indies, Australia and Sri Lanka (all have been at or near the top even though they might not be there in recent times). Our dataset will have the team names as a column so we can filter them out later if needed and the advantage is that we get a larger sample size which can (hopefully) make our prediction model stronger.

However, we have to limit ourselves to first innings only because during the 2nd innings, the final score has an upper bound (i.e. the target for the chasing team). This could be a big factor in determining the chasing team's approach and we want to avoid that biasing our sample.

# Putting the Dataset together
We have more than 1600 `.csv` files with ball-by-ball data in our collection for all T20Is played since the start of the format. From those, we only really need three things:

1. Powerplay total
2. Powerplay wickets
3. Final Score

So, we'll first filter the `match_id` from our master file which has summary information about each game we have ball-by-ball data for. We'll use the master file to filter out the games containing our chosen 8 teams where they played against each other. This will ensure that the quality of teams remains consistent.

Once we have the `match_id` column that we need, we'll use it to call each `.csv` as they are named according to their `match_id`. We'll read each file and pull out the required three bits of information. When we have the three bits, we'll split them into two tables, one for the end of the Powerplay and one for the final ball of the innings.


```{r data_full, cache=TRUE}
corr_games <-
  all_data %>%
  arrange(.,date) %>%
  filter(outcome != "no result" | is.na(outcome) ) %>%
  filter(date >= lubridate::ymd("1999-01-01") & date <= lubridate::ymd("2022-10-16")) %>%
  filter( team1 %in% c("Pakistan","England","India","New Zealand", "South Africa", "Australia", "Sri Lanka", "West Indies")) %>%
  filter( team2 %in% c("Pakistan","England","India","New Zealand", "South Africa", "Australia", "Sri Lanka", "West Indies")) %>%
  select(.,-season) %>%
  select(c(1:11))

filenames <- paste0(here("static", "data", "t20s_male_csv2", corr_games$match_id), ".csv")

corr_data <- list()
corr_data <- 
  lapply(filenames,read_csv,show_col_types=FALSE) %>%
  lapply(.,filter, innings==1) %>%
  lapply(., 
         mutate,
         total = cumsum(runs_off_bat + extras),
         wickets=ifelse(is.na(player_dismissed),0,1),
         balls = as.integer(ball) * 6 + (ball - as.integer(ball)) * 10,
         ) %>%
  #lapply(.,mutate, wkt_balls = ifelse(wickets==0,0,(120-balls) * (wickets+1))) %>%
  lapply(.,mutate, wickets = cumsum(wickets)) %>%
  lapply(.,filter, between(ball,5,6) | ball == max(ball)) %>%
  lapply(slice, (n()-1):n()) %>%
  lapply(select,-season) %>%
  bind_rows()

x <- corr_data %>%
  filter(ball < 6)
x$wickets = 10-x$wickets

y <- corr_data %>%
  filter(ball > 6)

ds <- tibble(id= y$match_id, final=y$total, PP_score = x$total, PP_wkt=x$wickets, t=x$total*x$wickets, team=y$batting_team)
```

# Analysis
Now that we have the data all set up, we can start the analysis. The first order of business is figuring out the correlation between the independent variables. This is pretty simple in `R`, all we need is the `cor.test()` function which is part of the `stats` pacakge loaded by default in `R` when it starts.

## Correlation between variables
``` {r correlation, include= TRUE}
cor.test(x$wickets, x$total)
```
As we can see, the correlation between the variables that are supposed to be independent is quite high. We have two options here:

1. Drop one of the variables, or
2. Combine them into a new variable

We'll take the second option as we do not want to rid ourselves of any predictive power of one of the variables. To combine the two variables, we'll simply multiply them and create a new variable called `t`. This new variable works well enough for our purpose, because it  allows us to have both variables present in our regression. But it also means that we can't separate the impact of each element. At this point, we're happy with the trade-off but this can be revisited later.

## Building the Regression

Now that we have dealt with the issue of correlated variables, we can turn our attention to the type of regression that'll be best for our purposes. Let's first take graph the data to get a visual idea of what we're dealing with.
``` {r include=TRUE}
ds %>% ggplot(aes(x = t, y = final)) +
  geom_point() +
  geom_smooth(method="lm", formula= y~x) + 
  theme_economist() 
```
As we can clearly see, there is a linear trend present. However, we should also note the variance present alongside the trend. If we take any value of `t` and visualize the difference between the top and the bottom value on the y-axis, the difference is quite large. So, we should expect our linear model to not do very well in terms of having a high R<sup>2</sup> value. This makes sense too, because the Powerplay is just 6 overs out of 20 in an innings and even with field restrictions it can't be expected to fully dictate the outcome of an innings. 

We'll try some non-linear, non-parametric methods as well to fit our data and see if they can do better than our simple model. Namely, we'll use loess regression, GAM regression, KNN means regression and SVM regression which are extensively used algorithms in the ML world (more for classification purposes, but also used as regressions).

## Splitting Data

In order to test the forecasting accuracy of our models, we'll have to split our data into two parts. The first part will be used to estimate the data, and the second part will be used to test the accuracy of the forecasts against actual values. We'll arbitrarily use a split of 70-30, as that's the first one that popped in my mind :)

After splitting the data we'll build models of the types discussed above and measure them against each other according to their forecast accuracy. Since we'll be doing the same thing after the models are created, we'll again use the function building approach so that we don't have to write the same code every time.

We'll repeat this whole exercise (i.e. splitting the data, estimating the model and then testing) a 100 times as well. This is so that any bias in statistics that could creep in because a one-time sample being more favorable to any particular method is removed. Our sample is not too large so doing this 100 times should be enough.

```{r models, echo=TRUE, cache=TRUE}
#install caret, e1071, mgcv packages before running chunk

# function to test prediction accuracy
pred_acc <- function(model, data) {
    preds <- predict(model, newdata = data) %>% unname()
    errors <- (placeholder <- data$final - preds)
    return(errors)
}

all_median <- list()
all_mean <- list()
for (i in 1:100) {
  # splitting data
  set.seed(i) # set seed for reproducability
  train <- slice_sample(ds, prop=0.7)
  test <- anti_join(ds, train, by = "id")

  # creating models
  model_lm <- lm(final ~ t, data = train)
  model_loess <- loess(final ~ t, data = train, control = loess.control(surface = "direct"))
  model_knn <- caret::knnreg(final ~ t, data = train)
  model_svm <- e1071::svm(final ~ t,
                          data = train, kernel = "radial", epsilon = .1)
  model_gam <- mgcv::gam(final ~ s(t, bs = "ts"),
                         data = train, method="REML")

  all_mods <- lst(model_lm, model_loess, model_knn, model_svm, model_gam)

 
  sing_errors <- lapply(all_mods, pred_acc, test) %>% bind_cols()

  # get table
  all_median[[i]] <- (sing_errors %>%
    mutate_all(abs) %>%
    summarize_all(median))
  all_mean[[i]] <- sing_errors %>%
    mutate_all(abs) %>%
    summarize_all(mean)
}
```

```{r tables_errors, echo=FALSE}
table_err <- all_median %>%
  bind_rows() %>%
  summarize_all(mean)

table_err %>%
  gt %>% 
  tab_options(table.width = "100%") %>% 
  tab_header(title="Average of Median Absolute Errors") %>% 
  fmt_number(columns=everything(),decimals=1) %>%
  opt_row_striping(row_striping = TRUE) %>%
  cols_label(.list = structure(as.list(str_remove(colnames(table_err), ".*_")),
                               names = colnames(table_err)
                               )
             )

table_err <-all_mean %>%
  bind_rows() %>%
  summarize_all(mean)

table_err %>%
  gt %>% 
  tab_options(table.width = "100%") %>% 
  tab_header(title="Average of Mean Absolute Errors") %>% 
  fmt_number(columns=everything(),decimals=1) %>%
  opt_row_striping(row_striping = TRUE) %>%
  cols_label(.list = structure(as.list(str_remove(colnames(table_err), ".*_")),
                               names = colnames(table_err)
                               )
             )
```

